{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import scrapbook as sb\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "LEAKY_RELU_ALPHA = 0.3     # Keras default\n",
    "BATCH_NORM_MOMENTUM = 0.99 # Keras default\n",
    "\n",
    "conv_0_0_params = dict(filters=16)\n",
    "conv_0_1_params = dict(filters=16)\n",
    "conv_1_0_params = dict(filters=32)\n",
    "conv_1_1_params = dict(filters=32)\n",
    "\n",
    "pooling = 'max'\n",
    "reduce = 'flatten'\n",
    "extra_dense = False\n",
    "extra_dense_units = 128\n",
    "\n",
    "train_batch_size = 10\n",
    "num_epochs = 5\n",
    "\n",
    "eval_batch_size = 10\n",
    "prefetch_size = 100\n",
    "shuffle_buffer_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, info = tfds.load('fashion_mnist', split=['train', 'test'], with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/eager/custom_layers\n",
    "class ConvBlock(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 filters=16, \n",
    "                 kernel_size=3, \n",
    "                 strides=1,\n",
    "                 padding='same', \n",
    "                 activation='leaky_relu',\n",
    "                 batch_normalization=True, \n",
    "                 conv_first=True):\n",
    "        \"\"\"2D Convolution -> Batch Normalization -> Activation stack builder\n",
    "\n",
    "        # Arguments\n",
    "            ## Conv2D features:\n",
    "            num_filters (int): number of filters used by Conv2D\n",
    "            kernel_size (int): square kernel dimension\n",
    "            strides (int): square stride dimension\n",
    "            padding (str): one of 'same' or 'valid'\n",
    "\n",
    "            ## Other cell features\n",
    "            activation (string): name of activation function to be used or None\n",
    "            batch_normalization (bool): whether to use batch normalization\n",
    "            conv_first (bool): conv -> bn         -> activation, if True; \n",
    "                               bn   -> activation -> conv,       if False\n",
    "        \"\"\"\n",
    "        super(ConvBlock, self).__init__(name='')\n",
    "\n",
    "        self.conv_first = conv_first\n",
    "        self.conv = tf.keras.layers.Conv2D(\n",
    "            filters, \n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding)\n",
    "        \n",
    "        if batch_normalization:\n",
    "            self.batch_norm = \\\n",
    "                tf.keras.layers.BatchNormalization(momentum=BATCH_NORM_MOMENTUM)\n",
    "        else:\n",
    "            self.batch_norm = None\n",
    "        \n",
    "        # Determine which activation function to use:\n",
    "        if isinstance(activation, str):\n",
    "            if activation.lower() == 'leaky_relu':\n",
    "                self.activation_fn = \\\n",
    "                    tf.keras.layers.LeakyReLU(alpha=LEAKY_RELU_ALPHA)\n",
    "            else:\n",
    "                self.activation_fn = \\\n",
    "                    tf.keras.layers.Activation(activation) # May raise an error\n",
    "        else:\n",
    "            self.activation_fn = None\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = input_tensor\n",
    "        if self.conv_first:\n",
    "            x = self.conv(x)\n",
    "            if self.batch_norm is not None:\n",
    "                x = self.batch_norm(x, training=training)\n",
    "            if self.activation_fn is not None:\n",
    "                x = self.activation_fn(x)\n",
    "        else:\n",
    "            if self.batch_norm is not None:\n",
    "                x = self.batch_norm(x, training=training)\n",
    "            if self.activation_fn is not None:\n",
    "                x = self.activation_fn(x)\n",
    "            x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the pooling method\n",
    "if pooling.lower() == 'max':\n",
    "    Pooling2D = tf.keras.layers.MaxPooling2D\n",
    "else:\n",
    "    assert (pooling.lower() == 'average')\n",
    "    Pooling2D = tf.keras.layers.AveragePooling2D\n",
    "    \n",
    "# Select reduce method\n",
    "if reduce.lower() == 'flatten':\n",
    "    Reduce = tf.keras.layers.Flatten\n",
    "else:\n",
    "    assert (reduce.lower() == 'gap')\n",
    "    Reduce = tf.keras.layers.GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = inputs\n",
    "x = ConvBlock(**conv_0_0_params)(x)    # conv_0_0\n",
    "x = ConvBlock(**conv_0_1_params)(x)    # conv_0_1\n",
    "x = Pooling2D()(x)\n",
    "x = ConvBlock(**conv_1_0_params)(x)    # conv_1_0\n",
    "x = ConvBlock(**conv_1_1_params)(x)    # conv_1_1\n",
    "x = Reduce()(x)\n",
    "if extra_dense == True:\n",
    "    x = tf.keras.layers.Dense(extra_dense_units)(x)\n",
    "x = tf.keras.layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_count = model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train, fashion_test = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(example):\n",
    "    return example[\"image\"] / 255, example[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_train = fashion_train.shuffle(shuffle_buffer_size).map(parser).batch(train_batch_size).prefetch(prefetch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_epoch = []\n",
    "loss = []\n",
    "accuracy = []\n",
    "for i in range(1, num_epochs + 1):\n",
    "    fashion_iterator = fashion_train.make_one_shot_iterator()\n",
    "    \n",
    "    start = time.time()\n",
    "    hist = model.fit(x=fashion_iterator, steps_per_epoch=60000 // train_batch_size, epochs=1)\n",
    "    end = time.time()\n",
    "    \n",
    "    time_per_epoch.append(end - start)\n",
    "    loss.append(hist.history['loss'][0])\n",
    "    accuracy.append(hist.history['acc'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_test = fashion_test.map(parser).batch(eval_batch_size).prefetch(prefetch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iterator = fashion_test.make_one_shot_iterator()\n",
    "eval_results = model.evaluate(x=test_iterator, steps=10000 // eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"time_per_epoch\", time_per_epoch)\n",
    "sb.glue(\"loss\", loss)\n",
    "sb.glue(\"accuracy\", accuracy)\n",
    "sb.glue(\"param_count\", param_count)\n",
    "sb.glue(\"eval_results\", eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
